ahmedsaleh243

Automatically generated by Colab.
Original file is located at
https://colab.research.google.com/drive/17xCjRGmuUn2uOftw4wSBt2BKLjF_lERs#scrollTo=3ampK8HDa-rh&line=89&uniqifier=1

# 
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
import numpy as np
from PIL import Image
import os
import random

# 
base_dir = "chest_xray"
splits = ["train", "validation", "test"]
categories = ["PNEUMONIA", "NORMAL"]

for split in splits:
    for category in categories:
        os.makedirs(os.path.join(base_dir, split, category), exist_ok=True)

# 
def create_dummy_images(path, num_images=50):
    for i in range(num_images):
        img = np.random.randint(0, 256, (150, 150, 3), dtype=np.uint8)
        im = Image.fromarray(img)
        im.save(os.path.join(path, f"img_{i}.png"))

# 
for category in categories:
    create_dummy_images(os.path.join(base_dir, "train", category), num_images=100)
    create_dummy_images(os.path.join(base_dir, "validation", category), num_images=40)
    create_dummy_images(os.path.join(base_dir, "test", category), num_images=40)

# 
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    os.path.join(base_dir, "train"),
    target_size=(150, 150),
    batch_size=16,
    class_mode='binary'
)

validation_generator = test_datagen.flow_from_directory(
    os.path.join(base_dir, "validation"),
    target_size=(150, 150),
    batch_size=16,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    os.path.join(base_dir, "test"),
    target_size=(150, 150),
    batch_size=16,
    class_mode='binary',
    shuffle=False
)

# 
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    BatchNormalization(),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# 
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples//train_generator.batch_size,
    epochs=9,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples//validation_generator.batch_size
)

# 
test_loss, test_acc = model.evaluate(test_generator)
print(f"Test Accuracy: {test_acc*100:.2f}%")
print(f"Test Loss: {test_loss:.4f}")
